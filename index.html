<!DOCTYPE HTML>
<!-- based on html5up.net templates-->
<html>
	<head>
	  <title> Victoria Firsanova </title>
	  <meta charset="utf-8" />
	  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	  <link rel="stylesheet" href="assets/css/main.css" />
	  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" />
	</head>
	<body class="is-preload">
	<!-- Wrapper -->
	  <div id="wrapper">
		<!-- Header -->
		<header id="header">
		  <div class="logo">
			<span class="icon fa fa-cube"></span>
		  </div>
		  <div class="content">
			<div class="inner">
			  <h1>Victoria Firsanova</h1>
			  <p>PhD Student at <a href="https://spbu.ru/">Saint Petersburg State University</a></p>
			</div>
		  </div>
		  <nav>
			<ul>
			  <li><a href="#portfolio">Portfolio</a></li>
			  <li><a href="#cv">CV</a></li>
			  <li><a href="#about">About</a></li>
			  <li><a href="#talks">Talks</a></li>
			</ul>
		  </nav>
		  <!-- Blog -->
		  <div class="blog">
		  	<h1 class="blog-title">BLOG</h1>
		  	<h2>How to Train a Convolutional Neural Network for Sentiment Analysis</h2>
		  	<p>One of the questions I get asked all the time is what is the best way to start practicing Machine Learning (ML). I wish I had known the answer when I was training my first neural network model! Honestly, I'm a practicing ML researcher and educator, and I still do not have the answer. Right or wrong, I usually suggest newbies trying to train a Convolutional Neural Network (CNN). This elegant architecture helped me get the intuition behind ML. In this post, we'll go through the steps to train a CNN for sentiment analysis using Python. Sentiment analysis is a popular Natural Language Processing (NLP) task that involves classifying text into categories such as positive, negative, or neutral.</p>
		  	<p><a href="https://vifirsanova.github.io/conv-net/">Read more..</a></p>
		  </div>
		  <!-- Social -->
		  <div class="social-links">
			<a href="https://www.youtube.com/channel/UCTBcWSrPpxINOBClyxM8CKg"><i class="fa fa-youtube"></i></a>
			<a href="https://twitter.com/vifirsanova"><i class="fa fa-twitter"></i></a>
			<a href="https://github.com/vifirsanova/"><i class="fa fa-github"></i></a>
			<a href="https://www.linkedin.com/in/victoria-firsanova-8795301b2/"><i class="fa fa-linkedin"></i></a>
			<a href="https://vk.com/missvector"><i class="fa fa-vk"></i></a>
			<a href="https://codepen.io/vifirsanova"><i class="fa fa-codepen"></i></a>
		  </div>
		</header>
		<!-- Main -->
		<div id="main">
		  <!-- Portfolio -->
		  <article id="portfolio">
			<h2 class="major">Portfolio</h2>
			</ul>
			<h3>Teaching</h3>
			<ul>
				<li><p class='left-align'><strong>2023-2024</strong> Python – MA program, Computational Linguistics
				<br><em>Higher School of Economics</em>
				<li><p class='left-align'><strong>2023-2024</strong> Digital Literacy – BA program, Media Communication
				<br><em>Higher School of Economics</em>
				<li><p class='left-align'><strong>2023-2024</strong> Computational Linguistics – BA program, Philology
				<br><em>Higher School of Economics</em>
				<li><p class='left-align'><strong>2023-2024</strong> Projects – "Developing a model for question answering and navigation for Hermitage visitors"; "Developing a chatbot for movie search"
				<br><em>Higher School of Economics</em>
			</ul>
			<h3>Recent Projects</h3>
			<ul>
			<li><p class='left-align'><strong>TranscribePro</strong><br><em>A mobile app for supporting inclusive education through Text-to-Speech (TTS) and Speech-to-Text (STT) technologies. Current state: prototyping.</em><br><a href="https://youtu.be/YpFz3ifhT54">Learn more</a></em></p></li>
			<li><p class='left-align'><strong>Virtual Teaching Assistant</strong><br><em>A web app adapting Large Langusge Models (LLMs) for educators. Current state: prototyping.</em><br><a href="https://youtu.be/YpFz3ifhT54">Learn more</a></em></p></li>
			<li><p class='left-align'><strong>EMPI AI Ecosystem</strong><br><em>A set of tools, including mobile apps, web apps, and a smart watch for supporting inclusive education. Current state: prototyping.</em><br><a href="https://vifirsanova.github.io/empi-web/">Learn more</a></em></p></li>
			<li><p class='left-align'><strong>The Black Box</strong><br><em>A popular science podcast about Artificial Intelligence for Russian-speaking audience.<br></em><a href="https://vk.link/the_black_box_podcast">Learn more</a></em></p></li>
			<li><p class='left-align'><strong>Text-to-Image XAI</strong><br><em>Experiments on text-to-image AI that combine knowledge from linguistics and computing. A contribution to the black box problem</em><br><a href="https://www.mathnet.ru/links/53e0bc8bbb04e56ca9a1601e12de44c8/znsl7425.pdf"> Learn more</a></p></li>
			</ul>
			<h3>Selected Papers</h3>
			<ul><li><p class='left-align'><a href='https://dl.acm.org/doi/10.1145/3543873.3587533'>Towards Building a Mobile App for People on the Spectrum</a><br>Victoria Firsanova<br>Companion Proceedings of the ACM Web Conference 2023, Austin, TX, USA.<br><em>The inclusion of autistic people can be augmented by a mobile app that provides information without a human mediator making information perception more liberating for people in the spectrum. This paper is an overview of a doctoral work dedicated to the development of a web-based mobile tool for supporting the inclusion of people on the autism spectrum. The work includes UX/UI research conducted with psychiatry experts, web information retrieval study and neural question-answering research. Currently, the study results comprise several mobile app layouts, a retriever-reader model design and fine-tuned neural network for extractive question-answering. Source code and other resources are available at https://github.com/vifirsanova/empi.</em></p></li>
			<li><p class='left-align'><a href='https://www.mathnet.ru/links/0a45d09db2dd574ebb64281a6f2e591a/znsl7425.pdf'>What do text-to-image models know about the languages of the world?</a><br>Victoria Firsanova<br>Data-Centric AI Workshop, 35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia.<br><em>Text-to-image models use user-generated prompts to produce images. Such text-to-image models as DALL-E 2, Imagen, Stable Diffusion, and Midjourney can generate photorealistic or similar to human-drawn images. Apart from imitating human art, large text-to-image models have learned to produce combinations of pixels reminiscent of captions in natural languages. For example, a generated image might contain a figure of an animal and a symbol combination reminding us of human-readable words in a natural language describing the biological name of this species. Although the words occasionally appearing on generated images can be human-readable, they are not rooted in natural language vocabularies and make no sense to non-linguists. At the same time, we find that semiotic and linguistic analysis of the so-called hidden vocabulary of text-to-image models will contribute to the field of explainable AI and prompt engineering. We can use the results of this analysis to reduce the risks of applying such models in real life problem solving and to detect deepfakes. The proposed study is one of the first attempts at analyzing text-to-image models from the point of view of semiotics and linguistics. Our approach implies prompt engineering, image generation, and comparative analysis. The source code, generated images, and prompts have been made available at https://github.com/vifirsanova/text-to-image-explainable.</em></p></li>
			<li><p class='left-align'><a href='https://datacentricai.org/neurips21/papers/123_CameraReady_NeurIPS_2021.pdf'>Two Approaches to Building Dialogue Systems for People on the Spectrum</a><br>Victoria Firsanova<br>Data-Centric AI Workshop, 35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia.<br><em>The paper presents a study on combining model- and data-centric approaches to building a question answering system for inclusion of people with autism spectrum disorder. The study shows that applying sequentially model- and data-centric approaches might allow achieving higher metric scores on closed-domain lowresourced datasets.</em></p></li>
			<li><p class='left-align'><a href='https://doi.org/10.1007/978-3-030-93715-7_9'>Transformer Models for Question Answering on Autism Spectrum Disorder QA Dataset</a><br>Victoria Firsanova<br>Springer International Publishings, Digital Transformation and Global Society: 6th International Conference, St. Petersburg, Russia.<br><em>Question answering (QA) Transformer-based models might become efficient in inclusive education. For example, one can test and tune such models with small closed-domain datasets before the implementation of a new system in an inclusive organization. However, studies in the sociomedical domain show that such models can be unpredictable. They can mislead a user or evoke aversive emotional states. The paper addresses the problem of investigating safety-first QA models that would generate user-friendly outputs. The study aims to analyze the performance of SOTA Transformer-based QA models on a custom dataset collected by the author of the paper. The dataset contains 1 134 question-answer pairs about autism spectrum disorders (ASD) in Russian. The study presents the validation and evaluation of extractive and generative QA models. The author used transfer learning techniques to investigate domain-specific QA properties and suggest solutions that might provide higher QA efficiency in the inclusion. The study shows that although generative QA models can misrepresent facts and generate false tokens, they might bring diversity in the system outputs and make the automated QA more user-friendly for younger people. Although extractive QA is more reliable, according to the metric scores presented in this study, such models might be less efficient than generative ones. The principal conclusion of the study is that a combination of generative and extractive approaches might lead to higher efficiency in building QA systems for inclusion. However, the performance of such combined systems in the inclusion is yet to be investigated.
</em></p></li>
		  </article>
		  <!-- CV -->
		  <article id="cv">
			<h2 class="major">CV</h2>
			<iframe src="https://vifirsanova.github.io/cv/Academic_CV.pdf" frameborder="0" width="100%" height="550px"></iframe>
		  </article>
		  <!-- About -->
		  <article id="about">
			<h2 class="major">About</h2>
			<p>This is how DALL·E 2 sees me!</p>
			<span class="image fit"><img src="assets/images/DALL·E 2023-05-12 23.58.38.png"><img src="assets/images/DALL·E 2023-05-12 23.57.32.png"><img src="assets/images/DALL·E 2023-05-12 23.57.54.png"></span>
			<p>Hello there, I am Victoria, and I'm self-taught AI researcher. At school, I was passionate about two things: computers and languages. I knew that computational linguistics is the perfect field for me, but I failed the exams to enter the desired faculty and started to study philology at university. Something was wrong. I was interested in linguistics but I felt nauseous about the other humanities. At one summer school, a guy advised me to walk through Stanford's natural language processing course. I spent nights learning the algorithms and mathematics behind language models and machine learning. I was extremely insecure about my skills until my paper was accepted to a NeurIPS workshop. </p>
		  </article>
		  <!-- Contact -->
		  <article id="talks">
			<h2 class="major">Recent Talks | YouTube</h2>
			<div class = "video-container">
			<iframe width="760" height="308" src="https://www.youtube.com/embed/DIqLXriu9Sc" title="Видео-визитка" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
		    </div>
			<div class = "video-container">
			<iframe width="760" height="308" src="https://www.youtube.com/embed/Rsvr-3KnslA" title="Виктория Фирсанова — Мой первый краудсорсинг: где брать данные, если твой проект уникален" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
		    </div>
			<div class = "video-container">
			<iframe width="760" height="308" src="https://www.youtube.com/embed/llb10MxQt14" title="Эволюция чат-ботов. Лекторий ОЛИМП" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
		    </div>
		  </article>
		</div>
		<!-- Footer -->
		<footer id="footer">
		  <p>Victoria Firsanova &copy; 2023</p>
		</footer>
	  </div>
	  <script src="assets/js/jquery.min.js"></script>
	  <script src="assets/js/browser.min.js"></script>
	  <script src="assets/js/breakpoints.min.js"></script>
	  <script src="assets/js/main.js"></script>
	</body>
</html>
